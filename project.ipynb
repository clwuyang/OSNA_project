{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task: Fake News Classification \n",
    "Social media has become one of the major resources for people to obtain news and information. For\n",
    "example, it is found that social media now outperforms television as the major news source. However,\n",
    "because it is cheap to provide news online and much faster and easier to disseminate through social\n",
    "media, large volumes of fake news or misinformation are produced online for a variety of purposes,\n",
    "such as financial and political gain. The extensive spread of fake news/misinformation can have a\n",
    "serious negative impact on individuals and society: (i) breaking the authenticity balance of the news\n",
    "ecosystem; (ii) intentionally persuading consumers to accept biased or false beliefs; and (iii) changing\n",
    "the way people interpret and respond to real news and information. Therefore, it is important to\n",
    "detect fake news and misinformation in social media.\n",
    "We formally define the task as follow. Given the title of a fake news article A and the title of a\n",
    "coming news article B, participants are asked to classify B into one of the three categories:\n",
    "\n",
    "* agreed: B talks about the same fake news as A. \n",
    "\n",
    "* disagreed: B refutes the fake news in A. \n",
    "\n",
    "* unrelated: B is unrelated to A. \n",
    "\n",
    "\n",
    "# File Descriptions\n",
    "In the attached folder, you are provided with 3 CSV files:\n",
    "* train.csv: Training data\n",
    "* test.csv: Test data\n",
    "* sample submission.csv: Expected submission format\n",
    "\n",
    "\n",
    "The training data includes the “label” of each news pair, while the test data doesn’t. Validation data\n",
    "can be split from train.csv. Students should use the training data to train a classifier and evaluate\n",
    "their model’s performance with the validation data. Finally, by using the trained model, you are\n",
    "required to predict the results for the test data. The format of your output file should be the same as\n",
    "“sample submission.csv” with your prediction replaced in“lable” column.\n",
    "The columns in train and test data are as follows:\n",
    "\n",
    "* id: the id of each news pair.\n",
    "* tid1: the id of fake news title 1.\n",
    "* tid2: the id of news title 2.\n",
    "* title1 en: the fake news title 1 in English.\n",
    "* title2 en: the news title 2 in English.\n",
    "* label: indicates the relation between the news pair: agreed/disagreed/unrelated\n",
    "\n",
    "\n",
    "# Submission\n",
    "Students are supposed to submit the result file (named “submission.csv”), source code, presentation\n",
    "slides and report in one .zip file named LASTNAME1 LASTNAME2 PJ2 (Instead of LASTNAME1\n",
    "and LASTNAME2 type the lastname of each member). The submitted results should be reproducible\n",
    "with the submitted code/data. Moreover, do not change the name of the files as your submitted .csv\n",
    "file will pass an automatic program. The report should not be less than 2 pages and should include\n",
    "description of the data pre-processing, model, and validation results. Use a “Reference” section and\n",
    "cite all the papers, tutorials, packages, software and libraries you used for your program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import zipfile\n",
    "import datetime\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from pytorch_pretrained_bert) (2.28.1)\n",
      "Collecting torch>=0.4.1\n",
      "  Downloading torch-2.0.0-cp39-none-macosx_11_0_arm64.whl (55.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex\n",
      "  Downloading regex-2023.3.23-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.9/288.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from pytorch_pretrained_bert) (4.64.1)\n",
      "Requirement already satisfied: numpy in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from pytorch_pretrained_bert) (1.23.2)\n",
      "Requirement already satisfied: boto3 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from pytorch_pretrained_bert) (1.24.75)\n",
      "Requirement already satisfied: typing-extensions in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (4.3.0)\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.1.2)\n",
      "Requirement already satisfied: networkx in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from torch>=0.4.1->pytorch_pretrained_bert) (2.8.8)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from boto3->pytorch_pretrained_bert) (0.6.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from boto3->pytorch_pretrained_bert) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.75 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from boto3->pytorch_pretrained_bert) (1.27.75)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->pytorch_pretrained_bert) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->pytorch_pretrained_bert) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->pytorch_pretrained_bert) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from requests->pytorch_pretrained_bert) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from botocore<1.28.0,>=1.27.75->boto3->pytorch_pretrained_bert) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from jinja2->torch>=0.4.1->pytorch_pretrained_bert) (2.1.1)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/cwuyang/miniforge3/envs/tensorflow/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.75->boto3->pytorch_pretrained_bert) (1.16.0)\n",
      "Installing collected packages: mpmath, sympy, regex, filelock, torch, pytorch_pretrained_bert\n",
      "Successfully installed filelock-3.11.0 mpmath-1.3.0 pytorch_pretrained_bert-0.6.2 regex-2023.3.23 sympy-1.11.1 torch-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 231508/231508 [00:00<00:00, 14053941.56B/s]\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello', 'we', 'are', 'cheng', '##long', 'and', 'ash', '##ik']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenized input\n",
    "text = \"Hello we are Chenglong and Ashik\"\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['label'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle1_en\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     13\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle2_en\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     14\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m train \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mloc[:, cols]\n\u001b[0;32m---> 16\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m train\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNKNOWN\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m test\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUNKNOWN\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexing.py:961\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[1;32m    960\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_value(\u001b[39m*\u001b[39mkey, takeable\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_takeable)\n\u001b[0;32m--> 961\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple(key)\n\u001b[1;32m    962\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[1;32m    964\u001b[0m     axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexing.py:1149\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take_opportunity(tup):\n\u001b[1;32m   1147\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_multi_take(tup)\n\u001b[0;32m-> 1149\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_tuple_same_dim(tup)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexing.py:827\u001b[0m, in \u001b[0;36m_LocationIndexer._getitem_tuple_same_dim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_null_slice(key):\n\u001b[1;32m    825\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m retval \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39;49m(retval, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\u001b[39m.\u001b[39;49m_getitem_axis(key, axis\u001b[39m=\u001b[39;49mi)\n\u001b[1;32m    828\u001b[0m \u001b[39m# We should never have retval.ndim < self.ndim, as that should\u001b[39;00m\n\u001b[1;32m    829\u001b[0m \u001b[39m#  be handled by the _getitem_lowerdim call above.\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[39massert\u001b[39;00m retval\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexing.py:1194\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(key, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m key\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1192\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index with multidimensional key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_iterable(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   1196\u001b[0m \u001b[39m# nested tuple slicing\u001b[39;00m\n\u001b[1;32m   1197\u001b[0m \u001b[39mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexing.py:1132\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_key(key, axis)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# A collection of keys\u001b[39;00m\n\u001b[0;32m-> 1132\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_listlike_indexer(key, axis)\n\u001b[1;32m   1133\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   1134\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_dups\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexing.py:1330\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1327\u001b[0m ax \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m   1328\u001b[0m axis_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis_name(axis)\n\u001b[0;32m-> 1330\u001b[0m keyarr, indexer \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49m_get_indexer_strict(key, axis_name)\n\u001b[1;32m   1332\u001b[0m \u001b[39mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexes/base.py:5796\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   5793\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   5794\u001b[0m     keyarr, indexer, new_indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 5796\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[1;32m   5798\u001b[0m keyarr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m   5799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, Index):\n\u001b[1;32m   5800\u001b[0m     \u001b[39m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/pandas/core/indexes/base.py:5859\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   5856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNone of [\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m] are in the [\u001b[39m\u001b[39m{\u001b[39;00maxis_name\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   5858\u001b[0m not_found \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]]\u001b[39m.\u001b[39munique())\n\u001b[0;32m-> 5859\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mnot_found\u001b[39m}\u001b[39;00m\u001b[39m not in index\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['label'] not in index\""
     ]
    }
   ],
   "source": [
    "#if os.path.isdir(\"../input/fake-news-pair-classification-challenge\"):\n",
    "TRAIN_CSV_PATH = '/Users/cwuyang/repositories/CS579/OSNA_project/option1-data(1)/train.csv'\n",
    "TEST_CSV_PATH = '/Users/cwuyang/repositories/CS579/OSNA_project/option1-data(1)/test.csv'\n",
    "\"\"\"    \n",
    "else:\n",
    "    TRAIN_CSV_PATH = '../input/train.csv'\n",
    "    TEST_CSV_PATH = '../input/test.csv'\n",
    "\"\"\"   \n",
    "    \n",
    "train = pd.read_csv(TRAIN_CSV_PATH, index_col='id')\n",
    "test = pd.read_csv(TEST_CSV_PATH, index_col='id')\n",
    "cols = ['title1_en', \n",
    "        'title2_en', \n",
    "        'label']\n",
    "train = train.loc[:, cols]\n",
    "test = test.loc[:, cols]\n",
    "train.fillna('UNKNOWN', inplace=True)\n",
    "test.fillna('UNKNOWN', inplace=True)\n",
    "train.head(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9087097a5a07378d4c99306759909929720e0930838ea0ec6dd1550237a3b605"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
